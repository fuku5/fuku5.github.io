<!-- DON'T EDIT THIS FILE -->
<!-- EDIT index.md and run make.py -->
<div id="header" class="clearfix">
<h1 id="my_name"> Fukuchi, Yosuke</h1>
<div id="header_right">
<a href="https://scholar.google.co.jp/citations?user=If95M5sAAAAJ">[Google Scholar]</a>
<a href="https://orcid.org/0000-0002-7514-9040">[ORCID]</a>
<br>
<img src="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=If95M5sAAAAJ&citpid=3" height="128" width="108">
</div>
</div>

<div style="text-align: right;">
<!--
Imai Laboratory, Dept. of Information & Computer Science, Faculty of Science & Technology, Keio University<br>
3-14-1 Hiyoshi, Kohoku-ku, Yokohama, Kanagawa 223-8522, Japan<br>
Email: fukuchi (at) ailab.ics.keio.ac.jp 
-->
Seiji Yamada Laboratory, Digital Content and Media Sciences Research Division, National Institute of Informatics (NII), Japan.<br>
Email: fukuchi (at) nii.ac.jp <br>
(Last updated: 2023/03/07)
</div>




## Research Interests
- Human-AI interaction. Computational models of interaction for
  - mind-aware communication
  - human trust/reliance adjustment
  - applying AI systems to intelligent user interfaces

## Current Positions
- 2022 Apr. - Present **Project Researcher**, National Institute of Informatics, Japan.
- 2022 Oct. - Present **Part-time Lecturer**, Nihon University, Japan.

## Professional Experience
- 2021 Apr. - 2022 Mar. **Project Researcher**, Graduate School of Science and Engineering, Keio University, Japan.
- 2019 Apr. - 2021 Mar. **Assistant Professor**, Graduate School of Science and Engineering, Keio University, Japan.
- 2019 Apr. - 2019 Sep. **Teaching Assistant**, Tokyo University of Technology, Japan.
- 2017 Apr. - 2019 Mar. **Teaching Assistant**, Keio University, Japan.
- 2016 Apr. - 2019 Mar. **Collaborative Researcher**, Dwango artificial intelligence laboratory.

## Education
- 2023 Mar. **Ph.D. in Engineering**, Graduate School of Science and Engineering, Keio University, Japan.
- 2019 Apr. - 2022 Mar. **Finished Ph.D. program without dissertation**, Graduate School of Science and Engineering, Keio University, Japan.
- 2017 Apr. - 2019 Mar. **Master of Engineering**, Information and Conputer Science, Keio University, Japan.
- 2013 Apr. - 2017 Mar. **Bachelor of Engineering**, Information and Computer Science, Keio University, Japan.

## Membership
- 2018 Apr. - Present Young Researcher Association of Japanese Cognitive Science Society.
- 2017 Apr. - Present The Japanese Society for Artificial Intelligence

<!--
- 2018 Apr. - Present **Vice-chair**, Young Researcher Association of Japanese Cognitive Science Society.
-->

## Activities
- 2022 Dec. Workshop organizer (Cognitive Human-agent Interaction) at the International Conference of Human-agent Interaction 2022. 

## Publications
### Journal
1. Ryoichi Shibata, Shoya Matsumori, <span class="underdot">Yosuke Fukuchi</span>, Tomoyuki Maekawa, Mitsuhiko Kimoto, and Michita Imai,  "Conversational Context-Sensitive Ad Generation With a Few Core-Queries",  ACM Transactions on Interactive Intelligent Systems (TiiS)  2023. (accepted)
1. Shoya Matsumori, Kohei Okuoka, Ryoichi Shibata, Minami Inoue, <span class="underdot">Yosuke Fukuchi</span>, and Michita Imai,  "Mask and Cloze: Automatic Open Cloze Question Generation Using a Masked Language Model",  IEEE Access , vol. 11, p. 9835--9850 2023. doi: <a href="https://ieeexplore.ieee.org/document/10024779">10.1109/ACCESS.2023.3239005</a>
1. Riki Satogata, Mitsuhiko Kimoto, <span class="underdot">Yosuke Fukuchi</span>, Kohei Okuoka, and Michita Imai,  "Q-Mapping: Learning User-Preferred Operation Mappings With Operation-Action Value Function",  IEEE Transactions on Human-Machine Systems , vol. 52, p. 1090--1102 2022. doi: <a href="https://ieeexplore.ieee.org/document/9903483">10.1109/THMS.2022.3207372</a>
1. <span class="underdot">Yosuke Fukuchi</span>, Masahiko Osawa, Hiroshi Yamakawa, and Michita Imai,  "Explaining Intelligent Agent's Future Motion on Basis of Vocabulary Learning With Human Goal Inference",  IEEE Access , vol. 10, p. 54336--54347 2022. doi: <a href="https://ieeexplore.ieee.org/document/9777698">10.1109/ACCESS.2022.3176104</a>
1. <span class="underdot">Yosuke Fukuchi</span>, Masahiko Osawa, Hiroshi Yamakawa, Tatsuji Takahashi, and Michita Imai,  "Conveying Intention by Motions With Awareness of Information Asymmetry",  Frontiers in Robotics and AI , vol. 9 2022. doi: <a href="https://www.frontiersin.org/article/10.3389/frobt.2022.783863">10.3389/frobt.2022.783863</a>


### Conferences (Refereed)
1. Rintaro Hasegawa, <span class="underdot">Yosuke Fukuchi</span>, Kohei Okuoka, and Michita Imai,  "Advantage Mapping: Learning Operation Mapping for User-Preferred Manipulation by Extracting Scenes with Advantage Function",  Proceedings of the 10th International Conference on Human-Agent Interaction , p. 95--103, Association for Computing Machinery 2022. doi: <a href="https://doi.org/10.1145/3527188.3561917">10.1145/3527188.3561917</a> (Acceptance rate: 39%. <strong>Best paper award.</strong>)
1. Ryoichi Shibata, Shoya Matsumori, <span class="underdot">Yosuke Fukuchi</span>, Tomoyuki Maekawa, Mitsuhiko Kimoto, and Michita Imai,  "Utilizing Core-Query for Context-Sensitive Ad Generation Based on Dialogue",  27th International Conference on Intelligent User Interfaces , p. 734--745, Association for Computing Machinery 2022. doi: <a href="https://doi.org/10.1145/3490099.3511116">10.1145/3490099.3511116</a> (<strong>Acceptance rate: 24.5%.</strong>)
1. Yuta Watanabe, <span class="underdot">Yosuke Fukuchi</span>, Tomoyuki Maekawa, Shoya Matsumori, and Michita Imai,  "Inferring Human Beliefs and Desires from Their Actions and the Content of Their Utterances",  Proceedings of the 9th International Conference on Human-Agent Interaction , p. 391--395, Association for Computing Machinery 2021. doi: <a href="https://doi.org/10.1145/3472307.3484668">10.1145/3472307.3484668</a>
1. Teppei Yoshino, Shoya Matsumori, <span class="underdot">Yosuke Fukuchi</span>, and Michita Imai,  "Simultaneous Contextualization and Interpretation with Keyword Awareness",  Artificial Intelligence and Soft Computing , p. 403--413, Springer International Publishing 2021. doi: <a href="https://doi.org/10.1007%2F978-3-030-87897-9_36">10.1007/978-3-030-87897-9_36</a>
1. Shoya Matsumori, Kosuke Shingyouchi, Yuki Abe, <span class="underdot">Yosuke Fukuchi</span>, Komei Sugiura, and Michita Imai,  "Unified Questioner Transformer for Descriptive Question Generation in Goal-Oriented Visual Dialogue",  Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) , p. 1898--1907 2021. doi: <a href="https://ieeexplore.ieee.org/document/9710757">10.1109/ICCV48922.2021.00191</a> (<strong>Acceptance rate: 25.9%.</strong>)
1. Nanase Otake, Shoya Matsumori, <span class="underdot">Yosuke Fukuchi</span>, Yusuke Takimoto, and Michita Imai,  "Mixed Reference Interpretation in Multi-turn Conversation",  Proceedings of the 13th International Conference on Agents and Artificial Intelligence , SCITEPRESS - Science and Technology Publications 2021. doi: <a href="https://doi.org/10.5220%2F0010260103210328">10.5220/0010260103210328</a>
1. <span class="underdot">Yosuke Fukuchi</span>, Yusuke Takimoto, and Michita Imai,  "Adaptive Enhancement of Swipe Manipulations on Touch Screens with Content-awareness",  Proceedings of the 12th International Conference on Agents and Artificial Intelligence , {SCITEPRESS} - Science and Technology Publications 2020. doi: <a href="https://doi.org/10.5220%2F0008917804290436">10.5220/0008917804290436</a>
1. Shoya Matsumori, <span class="underdot">Yosuke Fukuchi</span>, Masahiko Osawa, and Michita Imai,  "Do Others Believe What {I} Believe?: Estimating How Much Information
is being Shared by Utterance Timing",  Proceedings of the 6th International Conference on Human-Agent Interaction,
{HAI} 2018, Southampton, United Kingdom, December 15-18, 2018 , p. 301--309, {ACM} 2018. doi: <a href="https://doi.org/10.1145/3284432.3284461">10.1145/3284432.3284461</a> (<strong>Long presentation acceptance rate: 29%.</strong>)
1. <span class="underdot">Yosuke Fukuchi</span>, Masahiko Osawa, Hiroshi Yamakawa, Tatsuji Takahashi, and Michita Imai,  "Bayesian Inference of Self-intention Attributed by Observer",  Proceedings of the 6th International Conference on Human-Agent Interaction , {ACM} 2018. doi: <a href="https://doi.org/10.1145%2F3284432.3284438">10.1145/3284432.3284438</a> (<strong>Long presentation acceptance rate: 29%.</strong>)
1. <span class="underdot">Yosuke Fukuchi</span>, Masahiko Osawa, Hiroshi Yamakawa, and Michita Imai,  "Application of Instruction-Based Behavior Explanation to a Reinforcement Learning Agent with Changing Policy",  Neural Information Processing , p. 100--108, Springer International Publishing 2017. doi: <a href="https://doi.org/10.1007%2F978-3-319-70087-8_11">10.1007/978-3-319-70087-8_11</a>
1. <span class="underdot">Yosuke Fukuchi</span>, Masahiko Osawa, Hiroshi Yamakawa, and Michita Imai,  "Autonomous Self-Explanation of Behavior for Interactive Reinforcement Learning Agents",  Proceedings of the 5th International Conference on Human Agent Interaction , {ACM} 2017. doi: <a href="https://doi.org/10.1145%2F3125739.3125746">10.1145/3125739.3125746</a>


### Preprints
1. <span class="underdot">Yosuke Fukuchi</span>, and Seiji Yamada,  "Selectively Providing Reliance Calibration Cues With Reliance Prediction",   , arXiv 2023. doi: <a href="https://arxiv.org/abs/2302.09995">10.48550/ARXIV.2302.09995</a>
1. Teppei Yoshino, <span class="underdot">Yosuke Fukuchi</span>, Shoya Matsumori, and Michita Imai,  "Chat, Shift and Perform: Bridging the Gap between Task-oriented and Non-task-oriented Dialog Systems",   , arXiv 2022. doi: <a href="https://arxiv.org/abs/2206.11813">10.48550/ARXIV.2206.11813</a>
1. Yusuke Takimoto, <span class="underdot">Yosuke Fukuchi</span>, Shoya Matsumori, and Michita Imai,  "SLAM-Inspired Simultaneous Contextualization and Interpreting for Incremental Conversation Sentences",   , arXiv 2020. doi: <a href="https://arxiv.org/abs/2005.14662">10.48550/ARXIV.2005.14662</a>


### Domestic conferences
1.  <span class="underdot">福地庸介</span>, and  山田誠二,  "信頼度推定にもとづく信頼較正キューの選択的提示",  HAIシンポジウム2023  2023. <a href="https://hai-conference.net/symp2023/proceedings/html/paper/paper-G-14.html">URL</a> (<strong>HAI-researcher Encouragement Award</strong>)
1. 松森 匠哉, 奥岡 耕平, 柴田 遼一, 井上 南, 吉野 哲平, <span class="underdot">福地 庸介</span>, 岩沢 透, and 今井 倫太,  "マスク言語モデルを利用したOpen Cloze問題の自動生成",  人工知能学会全国大会論文集 , vol. JSAI2022, p. 3N4GS1004--3N4GS1004 2022.
1.  長谷川麟太郎,  <span class="underdot">福地庸介</span>,  奥岡耕平, and  今井倫太,  "Advantage 関数を用いたコントローラキャリブレーションによるユーザ好みのマッピングの獲得",  第 84 回全国大会講演論文集 , vol. 2022, p. 39--40 2022.
1.  土屋碧渡,  川崎陽祐,  渡邊悠太,  佐藤夏樹,  <span class="underdot">福地庸介</span>,  松森匠哉,  前川知行,  髙橋正樹, and  今井倫太,  "買い物支援ロボットに向けた実世界における信念と欲求の逐次推定モデルの検討",  第 84 回全国大会講演論文集 , vol. 2022, p. 95--96 2022.
1.  土屋碧渡,  川崎陽祐,  渡邊悠太,  佐藤夏樹,  <span class="underdot">福地庸介</span>,  松森匠哉,  前川知行,  髙橋正樹, and  今井倫太,  "アクショングラフを用いた 「位置情報と発話内容をもとにした」 信念と欲求の推定システム",  電子情報通信学会技術研究報告; 信学技報 , 電子情報通信学会 2021.
1. 前川 知行, 松森 匠哉, <span class="underdot">福地 庸介</span>, and 今井 倫太,  "文脈の中で相互理解感を形作る推薦対話システム",  日本認知科学会第38回大会 , p. 40--46 2021.
1. 内海 佑麻, <span class="underdot">福地 庸介</span>, 木本 充彦, and 今井 倫太,  "曖昧性解消における視覚的注意へのトップダウン介入",  人工知能学会全国大会論文集 , vol. JSAI2021, p. 1H2GS1a04--1H2GS1a04 2021.
1. 柴田 遼一, 吉野 哲平, 松森 匠哉, <span class="underdot">福地 庸介</span>, 木本 充彦, and 今井 倫太,  "不完全な検索クエリにおける対話履歴からの検索ワード補完手法の検討",  情報処理学会第83回全国大会講演論文集 , vol. 2021, p. 411--412 2021. <a href="https://cir.nii.ac.jp/crid/1573668927856247424">URL</a>
1. 渡邊 悠太, <span class="underdot">福地 庸介</span>, 前川 知行, and 今井 倫太,  "行動情報と発話情報の組み合わせによる信念と欲求の逐次的推測モデルの検討",  情報処理学会第83回全国大会講演論文集 , vol. 2021, p. 211--212 2021. <a href="https://cir.nii.ac.jp/crid/1572824502926346240">URL</a>
1. 金沢 壮真, 松森 匠哉, 新行内 浩輔, <span class="underdot">福地 庸介</span>, and 今井 倫太,  "視覚情報を用いた対話型物体特定タスクにおける質問数削減手法の検討",  情報処理学会第83回全国大会講演論文集 , vol. 2021, p. 417--418 2021. <a href="https://cir.nii.ac.jp/crid/1574231877809662848">URL</a>
1. 宝田 悠, <span class="underdot">福地 庸介</span>, 今井 倫太, and 高橋 達二,  "情報の非対称性を含む Legible Motion に対する印象的評価の検証",  日本認知科学会第37回大会  2020.
1.  吉野哲平,  松森匠哉,  <span class="underdot">福地庸介</span>,  滝本佑介, and  今井倫太,  "SCAKE: 文脈と重要語の逐次的並列推定",  人工知能学会全国大会論文集 第 34 回 (2020) , p. 3Q1GS903--3Q1GS903 2020.
1. 本郷 望実, 松森 匠哉, <span class="underdot">福地 庸介</span>, 前川 知行, and 今井 倫太,  "対話支援に向けた言語情報と画像情報の対応付けによる話者のアテンション可視化",  人工知能学会研究会資料 言語・音声理解と対話処理研究会 , vol. 90, p. 20 2020.
1.  新行内浩輔,  松森匠哉,  <span class="underdot">福地庸介</span>,  阿部佑樹, and  今井倫太,  "分散表現空間内の文脈の推移に着目したワード人狼における発話分析",  人工知能学会全国大会論文集 第 34 回 (2020) , p. 3Q1GS904--3Q1GS904 2020.
1.  里形理興,  妹尾卓磨,  <span class="underdot">福地庸介</span>, and  今井倫太,  "Q-Mapping: 行動価値関数を利用したユーザ操作に対する解釈の適応的獲得",  人工知能学会全国大会論文集 , vol. 2020, p. 3Rin446--3Rin446, 一般社団法人 人工知能学会 2020.
1. 宝田 悠, <span class="underdot">福地 庸介</span>, 今井 倫太, and 高橋 達二,  "情報の非対称性を含む Legible Motion に対する印象的評価の検証",  日本認知科学会第36回大会  2019.
1.  里形理興,  滝口啓介,  <span class="underdot">福地庸介</span>, and  今井倫太,  "ユーザの閲覧行動に基づきパノラマ画像データを選択する適応型ストリートビューの開発",  人工知能学会全国大会論文集 第 33 回 (2019) , p. 1O2J1202--1O2J1202 2019.
1.  松森匠哉,  大澤正彦,  <span class="underdot">福地庸介</span>, and  今井倫太,  "ユーザモデルにもとづいて発言タイミングを決定するプレディクティブチャットボット",  第 80 回全国大会講演論文集 , vol. 2018, p. 419--420 2018.
1.  <span class="underdot">福地庸介</span>,  大澤正彦,  山川宏, and  今井倫太,  "人間の環世界から見たエージェントモデル--AI Safety の実現に向けて",  人工知能学会全国大会論文集 第 32 回 (2018) , p. 3J105--3J105 2018.
1. <span class="underdot">福地 庸介</span>, 大澤 正彦, 山川 宏, and 今井 倫太,  "異種エージェントへの教示に向けたInstruction-based Behavior Explanationの応用の検討",  人工知能学会第二種研究会資料 , vol. 2017, p. 07 2017.
1. <span class="underdot">福地 庸介</span>, 大澤 正彦, 岨野 太一, 山川 宏, and 今井 倫太,  "深層強化学習エージェントの自己モデル獲得と行動目標説明表現の生成",  人工知能学会第二種研究会資料 , vol. 2017, p. 08 2017.
1.  <span class="underdot">福地庸介</span>,  大澤正彦,  岨野太一,  山川宏, and  今井倫太,  "深層強化学習エージェントの自己モデルによる意図の解釈",  第 79 回全国大会講演論文集 , vol. 2017, p. 655--656 2017.


### Others
1. <span class="underdot">福地 庸介</span>, and 鳥羽山 莉沙,  "2019 年度日本認知科学会サマースクール参加報告",  認知科学 , vol. 26, p. 524--526, 日本認知科学会 2019.


## Grants
1. "心の読み合いにもとづく非言語表現の計算論的理解," KLL Ph.D. Program Research Grant, 300,000 JPY, 2021.
1. "説明可能AIの実現に向けた自律エージェントの行動説明表現の獲得," The Keio University Doctorate Student Grant-in-Aid Program from Ushioda Memorial Fund, 120,000 JPY, 2021.
