@ARTICLE{11015485,
  author={Pannattee, Peerawat and Fukuchi, Yosuke and Nishiuchi, Nobuyuki},
  journal={IEEE Access}, 
  title={MUXAS-VR: A Multi-Dimensional User Experience Assessment System for Virtual Reality}, 
  year={2025},
  volume={13},
  number={},
  pages={93063-93083},
  keywords={Visualization;Sensors;User experience;Solid modeling;Sensor phenomena and characterization;Physiology;Brain modeling;Electroencephalography;Emotional responses;Complexity theory;User experience;cybersickness;sense of presence;user satisfaction;virtual reality;machine learning;deep learning},
  doi={10.1109/ACCESS.2025.3573382}}

@ARTICLE{11006725,
  author={Khaesawad, Attaporn and Fukuchi, Yosuke and Yem, Vibol and Nishiuchi, Nobuyuki},
  journal={IEEE Access}, 
  title={Machine Learning-Based Classification of Programming Logic Understanding Levels by Mouse-Tracking Heatmaps}, 
  year={2025},
  volume={13},
  number={},
  pages={89905-89914},
  keywords={Programming profession;Heating systems;Block codes;Codes;Logic;Education;Encoding;Problem-solving;Machine learning;Computer languages;Block coding;machine learning;mouse-tracking heatmap;pattern classification;teacher support},
  doi={10.1109/ACCESS.2025.3571050}}
@INPROCEEDINGS{srithammee2025investigating,
  author={Srithammee, Nattamon and Pannattee, Peerawat and Fukuchi, Yosuke and Nishiuchi, Nobuyuki},
  booktitle={2025 17th International Conference on Knowledge and Smart Technology (KST)}, 
  title={Investigating the Impact of Sound Design on User Experience in Virtual Reality}, 
  year={2025},
  volume={},
  number={},
  pages={341-345},
  keywords={Statistical analysis;Cybersickness;Focusing;Virtual environments;Psychology;Particle measurements;User experience;Complexity theory;Quality of experience;Videos;Virtual Reality;User Experience;Sense of Presence;User Satisfaction;Sound Design},
  doi={10.1109/KST65016.2025.11003277}}


@inproceedings{10.2312:egve.20241400,
booktitle = {ICAT-EGVE 2024 - International Conference on Artificial Reality and Telexistence and Eurographics Symposium on Virtual Environments - Posters and Demos},
editor = {Tanabe, Takeshi and Yem, Vibol},
title = {Study on multiple-virtual body perception: Effects of different spatial presentation and command input methods},
author = {Serizawa, Masatoshi and Fukuchi, Yosuke and Yem, Vibol and Ikei, Yasushi and Nishiuchi, Nobuyuki},
year = {2024},
publisher = {The Eurographics Association},
ISSN = {1727-530X},
ISBN = {978-3-03868-246-2},
DOI = {10.2312/egve.20241400}
}
@inproceedings{10.2312:egve.20241362,
booktitle = {ICAT-EGVE 2024 - International Conference on Artificial Reality and Telexistence and Eurographics Symposium on Virtual Environments},
editor = {Hasegawa, Shoichi and Sakata, Nobuchika and Sundstedt, Veronica},
title = {XR remote dialogue system presenting speaker's expression using a real-space avatar robot},
author = {Yoneda, Yuto and Ojima, Yukiya and Fukuchi, Yosuke and Yem, Vibol and Ikei, Yasushi and Nishiuchi, Nobuyuki},
year = {2024},
publisher = {The Eurographics Association},
ISSN = {1727-530X},
ISBN = {978-3-03868-245-5},
DOI = {10.2312/egve.20241362}
}
@inproceedings{10.1145/3687272.3690879,
author = {Fukuchi, Yosuke and Yamada, Seiji},
title = {Towards Adaptive Explanation with Social Robot in Human-XAI Interaction},
year = {2024},
isbn = {9798400711787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687272.3690879},
doi = {10.1145/3687272.3690879},
abstract = {Communication robots have the potential to contribute to effective human-XAI interaction as an interface that goes beyond textual or graphical explanations. However, it is not clear how we can develop an adaptive strategy to use a robot’s physical and vocal expressions depending on the context in dynamic interactions. This paper proposes a method for a communication robot to decide where to emphasize XAI-generated explanations with physical expressions. In the method, a user model predicts the effect of emphasizing certain points on a user and aims to minimize the expected difference between predicted user decisions and AI-suggested ones. We conducted a user study to investigate how emphasis selection with our method affects the performance of user decisions. The results suggest that our method guides a part of users to better decisions when the performance of the AI suggestion is high.},
booktitle = {Proceedings of the 12th International Conference on Human-Agent Interaction},
pages = {353–355},
numpages = {3},
keywords = {Explainable AI, Human-XAI interaction, Intelligent decision-support system, Saliency map, Stock trading},
location = {Swansea, United Kingdom},
series = {HAI '24}
}
@inproceedings{10.1145/3687272.3688328,
author = {Maehigashi, Akihiro and Fukuchi, Yosuke and Yamada, Seiji},
title = {Effects of Presenting Multiple Types of AI Explanations for Visual Task},
year = {2024},
isbn = {9798400711787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687272.3688328},
doi = {10.1145/3687272.3688328},
abstract = {Explainable AI (XAI) has been developed to make AI understandable to humans by providing explanations of its outputs. However, multiple types of AI explanations displayed on a screen could distort users’ trust in AI and their decision to rely on it. This could lead to poor task performance. In this study, we experimentally investigated the influence of AI explanations on trust and acceptance of AI results using a visual task. As a result, we found that participants increased their trust and acceptance of AI results with multiple types of explanations even though this did not improve task performance. These results, showing over-trust and over-reliance in human-agent interaction, were discussed along with cognitive load and cognitive bias caused by XAI.},
booktitle = {Proceedings of the 12th International Conference on Human-Agent Interaction},
pages = {160–166},
numpages = {7},
keywords = {Cognitive bias, Cognitive load, Explanation, Trust, Visual task, XAI},
location = {Swansea, United Kingdom},
series = {HAI '24}
}
@article{icres2024,
      title={Should XAI Nudge Human Decisions with Explanation Biasing?},
      author={Yosuke Fukuchi and Seiji Yamada},
      year={2024},
	  booktitle={The 9th issue of the International Conference Series on Robot Ethics and Standards (ICRES)},
	  url={https://www.researchgate.net/publication/381320461_Should_XAI_Nudge_Human_Decisions_with_Explanation_Biasing}
}
@article{icres2024maehigashi,
      title={Investigating Impact of Robot Motion on AI Transparency and Trust in AI},
      author={Akihiro Maehigashi and Yosuke Fukuchi and Seiji Yamada},
      year={2024},
	  booktitle={The 9th issue of the International Conference Series on Robot Ethics and Standards (ICRES)}
}

@inproceedings{10.1145/3613905.3650802,
author = {Maehigashi, Akihiro and Fukuchi, Yosuke and Yamada, Seiji},
title = {Adjusting Amount of AI Explanation for Visual Tasks},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650802},
doi = {10.1145/3613905.3650802},
abstract = {Explainable AI (XAI) has been designed to render AI comprehensible to humans by providing explanations of its processes. However, an excessive amount of explanation can lead to cognitive overload in users and the development of inappropriate trust in AI. To explore the appropriate amount of explanation, this study investigated the effects of explanation type (AI attention heatmap, AI goal, and AI reliability) on trust in XAI for a traditional visual search task in Experiment 1, and the effects of presenting adjusted explanations on task performance for an applied task in Experiment 2. As a result, displaying AI results alone increased trust and task performance for a low-complexity task, and displaying AI results with AI attention heatmaps that have high interpretability increased trust and task performance for a high-complexity task. This study demonstrated the importance of adjusting the amount of AI explanation to develop trust appropriately and improve task performance.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {35},
numpages = {7},
pages = {1-7},
keywords = {AI attention heatmap, AI goal, AI reliability, Explanation, Interpretability, Trust, Visual identification, Visual search, XAI},
location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
series = {CHI EA '24}
}
@misc{fukuchi2024emphasis,
      title={Dynamic Explanation Emphasis in Human-XAI Interaction with Communication Robot}, 
      author={Yosuke Fukuchi and Seiji Yamada},
      year={2024},
      eprint={2403.14550},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
}

@INPROCEEDINGS{maehigashi2024ro-man,
  author={Maehigashi, Akihiro and Fukuchi, Yosuke and Yamada, Seiji},
  booktitle={2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN)}, 
  title={Empirical investigation of how robot head motion influences acceptance of heatmap-based XAI: Designing XAI with social robot}, 
  year={2024},
  volume={},
  number={},
  pages={344-350},
  keywords={Heating systems;Visualization;Head;Explainable AI;Social robots;Motion pictures;Behavioral sciences;Artificial intelligence;Robots},
  doi={10.1109/RO-MAN60168.2024.10731272}}
@INPROCEEDINGS{fukuchi2024dynamic,
  author={Fukuchi, Yosuke and Yamada, Seiji},
  booktitle={2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN)}, 
  title={User Decision Guidance with Selective Explanation Presentation from Explainable-AI}, 
  year={2024},
  volume={},
  number={},
  pages={338-343},
  keywords={Decision support systems;Accuracy;Artificial intelligence;Robots},
  doi={10.1109/RO-MAN60168.2024.10731188}}
@ARTICLE{10343151,
  author={Fukuchi, Yosuke and Yamada, Seiji},
  journal={IEEE Access}, 
  title={Dynamic Selection of Reliance Calibration Cues with AI Reliance Model}, 
  year={2023},
  volume={11},
  number={},
  pages={138870-138881},
  doi={10.1109/ACCESS.2023.3339548},
	url = {https://doi.org/10.1109/ACCESS.2023.3339548},
keywords = {Reliance calibration, reliance prediction, reliance calibration cue, trust calibration, explainable AI, human-AI interaction, human-AI collaboration},
  abstract={Understanding what an AI system can and cannot do is necessary for end-users to use the AI properly without being over- or under-reliant on it. Reliance calibration cues (RCCs) communicate an AI’s capability to users, resulting in optimizing their reliance on it. Previous studies have typically focused on continuously presenting RCCs, and although providing an excessive amount of RCCs is sometimes problematic, limited consideration has been given to the question of how an AI can selectively provide RCCs. This paper proposes vPred-RC, an algorithm in which an AI decides whether to provide an RCC and which RCC to provide. It evaluates the influence of an RCC on user reliance with a cognitive model that predicts whether a human will assign a task to an AI agent with or without an RCC. We tested vPred-RC in a human-AI collaborative task called the collaborative CAPTCHA (CC) task. First, our reliance prediction model was trained on a dataset of human task assignments for the CC task and found to achieve 83.5% accuracy. We further evaluated vPred-RC’s dynamic RCC selection in a user study. As a result, the RCCs selected by vPred-RC enabled participants to more accurately assign tasks to an AI when and only when the AI succeeded compared with randomly selected ones, suggesting that vPred-RC can successfully calibrate human reliance with a reduced number of RCCs. The selective presentation of RCCs has the potential to enhance the efficiency of collaboration between humans and AIs with fewer communication costs.},
}

@misc{interaction23_hongo,
	author={本郷 望実 and 前川 知行 and 松森 匠哉 and 福地 庸介 and 今井 倫太},
	title={購買行動を誘導する対話エージェントの立ち位置が買い物支援システムのユーザ評価に与える影響},
	year={2023},
	booktitle={INTERACTION 2023},
	publisher={一般社団法人情報処理学会シンポジウム},
	pages={1B-26}
}
@misc{p_and_p,
  author={福地 庸介},
  title={目標を考慮した指示表現の理解と学習 ー説明可能な知的エージェントに向けてー},
  year={2022},
  booktitle={日本認知科学会 知覚と行動モデリング（P&P）研究分科会},
}
@inproceedings{maehigashi2023modeling,
      title={Modeling Reliance on XAI Indicating Its Purpose and Attention}, 
      author={Akihiro Maehigashi and Yosuke Fukuchi and Seiji Yamada},
      year={2023},
      booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
	  volume={45},
	  pages={1929-1936},
	  url={https://escholarship.org/uc/item/1fx742xm},
}
@INPROCEEDINGS{maehigashi2023roman,
  author={Maehigashi, Akihiro and Fukuchi, Yosuke and Yamada, Seiji},
  booktitle={2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}, 
  title={Empirical investigation of how robot’s pointing gesture influences trust in and acceptance of heatmap-based XAI}, 
  year={2023},
  pages={2134-2139},
  doi={10.1109/RO-MAN57019.2023.10309507},
  url={https://doi.org/10.1109/RO-MAN57019.2023.10309507}
}

@article{corequery,
author = {Shibata, Ryoichi and Matsumori, Shoya and Fukuchi, Yosuke and Maekawa, Tomoyuki and Kimoto, Mitsuhiko and Imai, Michita},
title = {Conversational Context-Sensitive Ad Generation with a Few Core-Queries},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
pages = {1--37},
issn = {2160-6455},
url = {https://doi.org/10.1145/3588578},
doi = {10.1145/3588578},
abstract = {When people are talking together in front of digital signage, advertisements that are aware of the context of the dialogue will work the most effectively. However, it has been challenging for computer systems to retrieve the appropriate advertisement from among the many options presented in large databases. Our proposed system, the Conversational Context-sensitive Advertisement generator (CoCoA), is the first attempt to apply masked word prediction to web information retrieval that takes into account the dialogue context. The novelty of CoCoA is that advertisers simply need to prepare a few abstract phrases, called Core-Queries, and then CoCoA automatically generates a context-sensitive expression as a complete search query by utilizing a masked word prediction technique that adds a word related to the dialogue context to one of the prepared Core-Queries. This automatic generation frees the advertisers from having to come up with context-sensitive phrases to attract users’ attention. Another unique point is that the modified Core-Query offers users speaking in front of the CoCoA system a list of context-sensitive advertisements. CoCoA was evaluated by crowd workers regarding the context-sensitivity of the generated search queries against the dialogue text of multiple domains prepared in advance. The results indicated that CoCoA could present more contextual and practical advertisements than other web-retrieval systems. Moreover, CoCoA acquired a higher evaluation in a particular conversation that included many travel topics to which the Core-Queries were designated, implying that it succeeded in adapting the Core-Queries for the specific ongoing context better than the compared method without any effort on the part of the advertisers. In addition, case studies with users and advertisers revealed that the context-sensitive advertisements generated by CoCoA also had an effect on the content of the ongoing dialogue. Specifically, since pairs unfamiliar with each other more frequently referred to the advertisement CoCoA displayed, the advertisements had an effect on the topics about which the pairs spoke. Moreover, participants of an advertiser role recognized that some of the search queries generated by CoCoA fit the context of a conversation and that CoCoA improved the effect of the advertisement. In particular, they learned how to design of designing a good Core-Query at ease by observing the users’ response to the advertisements retrieved with the generated search queries.},
journal = {ACM Transactions on Interactive Intelligent Systems},
month = {sep},
articleno = {15},
numpages = {37},
keywords = {Dialogue, query generation, mask prediction, context, advertisement}
}
@ARTICLE{10024779,
  author={Matsumori, Shoya and Okuoka, Kohei and Shibata, Ryoichi and Inoue, Minami and Fukuchi, Yosuke and Imai, Michita},
  journal={IEEE Access}, 
  title={Mask and Cloze: Automatic Open Cloze Question Generation Using a Masked Language Model}, 
  year={2023},
  volume={11},
  number={},
  pages={9835-9850},
  doi={10.1109/ACCESS.2023.3239005},
  url={https://ieeexplore.ieee.org/document/10024779}
}

@inproceedings{10.1145/3527188.3561917,
author = {Hasegawa, Rintaro and Fukuchi, Yosuke and Okuoka, Kohei and Imai, Michita},
title = {Advantage Mapping: Learning Operation Mapping for User-Preferred Manipulation by Extracting Scenes with Advantage Function},
year = {2022},
isbn = {9781450393232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3527188.3561917},
doi = {10.1145/3527188.3561917},
abstract = {When a user manipulates a system, a user input through an interface, or an operation, is converted to the user’s intended action according to the mapping that links operations and actions, which we call “operation mapping”. Although many operation mappings are created by designers assuming how a typical user would operate the system, the optimal operation mapping may vary from user to user. The designer cannot prepare in advance all possible operation mappings. One approach to solve this problem involves autonomous learning of an operation mapping during the operation. However, existing methods require manual preparation of scenes for learning mappings. We propose advantage mapping, which enables the efficient learning of operation mappings. Working from the idea that scenes in which the user’s desired action is predictable are useful for learning operation mappings, advantage mapping extracts scenes according to the magnitude of entropy in the output of the action value function acquired from reinforcement learning. In our experiment, the user’s ideal operation mapping was more accurately obtained from the scenes selected by advantage mapping than from learning through actual play.},
booktitle = {Proceedings of the 10th International Conference on Human-Agent Interaction},
pages = {95–103},
numpages = {9},
keywords = {reinforcement learning, intelligent user interfaces, adaptive systems},
location = {Christchurch, New Zealand},
series = {HAI '22}
}

@ARTICLE{9903483,  author={Satogata, Riki and Kimoto, Mitsuhiko and Fukuchi, Yosuke and Okuoka, Kohei and Imai, Michita},  journal={IEEE Transactions on Human-Machine Systems},   title={Q-Mapping: Learning User-Preferred Operation Mappings With Operation-Action Value Function},   year={2022},  volume={52},  number={6},  pages={1090-1102},  doi={10.1109/THMS.2022.3207372},
url={https://ieeexplore.ieee.org/document/9903483}}

@ARTICLE{9777698,  author={Fukuchi, Yosuke and Osawa, Masahiko and Yamakawa, Hiroshi and Imai, Michita},  journal={IEEE Access},   title={Explaining Intelligent Agent's Future Motion on Basis of Vocabulary Learning With Human Goal Inference},   year={2022},  volume={10},  number={},  pages={54336-54347},  url={https://ieeexplore.ieee.org/document/9777698},  doi={10.1109/ACCESS.2022.3176104}}

@ARTICLE{10.3389/frobt.2022.783863,
  
AUTHOR={Fukuchi, Yosuke and Osawa, Masahiko and Yamakawa, Hiroshi and Takahashi, Tatsuji and Imai, Michita},   
	 
TITLE={Conveying Intention by Motions With Awareness of Information Asymmetry},      
	
JOURNAL={Frontiers in Robotics and AI},      
	
VOLUME={9},      
	
YEAR={2022},      
	  
URL={https://www.frontiersin.org/article/10.3389/frobt.2022.783863},       
	
DOI={10.3389/frobt.2022.783863},      
	
ISSN={2296-9144},   
   
ABSTRACT={Humans sometimes attempt to infer an artificial agent's mental state based on mere observations of its behavior. From the agent's perspective, it is important to choose actions with awareness of how its behavior will be considered by humans. Previous studies have proposed computational methods to generate such publicly self-aware motion to allow an agent to convey a certain intention by motions that can lead a human observer to infer what the agent is aiming to do. However, little consideration has been given to the effect of information asymmetry between the agent and a human, or to the gaps in their beliefs due to different observations from their respective perspectives. This paper claims that information asymmetry is a key factor for conveying intentions with motions. To validate the claim, we developed a novel method to generate intention-conveying motions while considering information asymmetry. Our method utilizes a Bayesian public self-awareness model that effectively simulates the inference of an agent's mental states as attributed to the agent by an observer in a partially observable domain. We conducted two experiments to investigate the effects of information asymmetry when conveying intentions with motions by comparing the motions from our method with those generated without considering information asymmetry in a manner similar to previous work. The results demonstrate that by taking information asymmetry into account, an agent can effectively convey its intention to human observers.}
}
@inproceedings{10.1145/3472307.3484668,
author = {Watanabe, Yuta and Fukuchi, Yosuke and Maekawa, Tomoyuki and Matsumori, Shoya and Imai, Michita},
title = {Inferring Human Beliefs and Desires from Their Actions and the Content of Their Utterances},
year = {2021},
isbn = {9781450386203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472307.3484668},
doi = {10.1145/3472307.3484668},
abstract = {To create dialogue systems that provide information a user needs to know at an opportune moment, it is important to infer the user’s mental states such as his/her beliefs and desires. There are two types of study on inferring beliefs and desires: one type infers them from actions and the other infers them from the content of utterances. However, a method to infer beliefs and desires from both kinds of inference in an integrated way has not yet been established. In this paper, we propose Multimodal Inference of Mind Simultaneous Contextualization and Interpreting (MIoM SCAIN), a system for sequentially inferring users’ beliefs and desires on the basis of their walking behaviors and the content of their utterances. In our evaluation, we compared inferences of MIoM SCAIN with those of baselines that use either walking behaviors or the content of utterances. MIoM SCAIN’s predictions showed more correlation with subjective judgements compared with the baselines, indicating that the inference of beliefs and desires from both walking behaviors and utterance content is possible.},
booktitle = {Proceedings of the 9th International Conference on Human-Agent Interaction},
pages = {391–395},
numpages = {5},
	keywords = {Theory of Mind, Dialogue system, Bayesian inference, Partially Observable Markov Decision Processes, Human Computer Interaction},
location = {Virtual Event, Japan},
series = {HAI '21}
}
@incollection{Yoshino_2021, doi = {10.1007/978-3-030-87897-9_36}, url = {https://doi.org/10.1007%2F978-3-030-87897-9_36}, year = 2021, publisher = {Springer International Publishing}, pages = {403--413}, author = {Teppei Yoshino and Shoya Matsumori and Yosuke Fukuchi and Michita Imai}, title = {Simultaneous Contextualization and Interpretation with Keyword Awareness}, booktitle = {Artificial Intelligence and Soft Computing}
}
@inproceedings{Otake_2021,
author={Nanase Otake. and Shoya Matsumori. and Yosuke Fukuchi. and Yusuke Takimoto. and Michita Imai.},
title={Mixed Reference Interpretation in Multi-turn Conversation},
booktitle={Proceedings of the 13th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
year={2021},
pages={321-328},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0010260103210328},
url = {https://doi.org/10.5220%2F0010260103210328}, 
isbn={978-989-758-484-8},
issn={2184-433X},
}
@InProceedings{Matsumori_2021_ICCV,
    author    = {Matsumori, Shoya and Shingyouchi, Kosuke and Abe, Yuki and Fukuchi, Yosuke and Sugiura, Komei and Imai, Michita},
    title     = {Unified Questioner Transformer for Descriptive Question Generation in Goal-Oriented Visual Dialogue},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {1898-1907},
  doi={10.1109/ICCV48922.2021.00191},
  url = {https://ieeexplore.ieee.org/document/9710757},
	keywords = {Open cloze test, automatic question generation, masked language model, field study}
}
@inproceedings{Fukuchi_2020,
author={Yosuke Fukuchi. and Yusuke Takimoto. and Michita Imai.},
title={Adaptive Enhancement of Swipe Manipulations on Touch Screens with Content-awareness},
booktitle={Proceedings of the 12th International Conference on Agents and Artificial Intelligence - Volume 2: ICAART},
year={2020},
pages={429-436},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0008917804290436},
isbn={978-989-758-395-7},
issn={2184-433X},
url={https://www.researchgate.net/publication/339990345_Adaptive_Enhancement_of_Swipe_Manipulations_on_Touch_Screens_with_Content-awareness}
}
@inproceedings{Fukuchi_2018,
author = {Fukuchi, Yosuke and Osawa, Masahiko and Yamakawa, Hiroshi and Takahashi, Tatsuji and Imai, Michita},
title = {Bayesian Inference of Self-Intention Attributed by Observer},
year = {2018},
isbn = {9781450359535},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3284432.3284438},
doi = {10.1145/3284432.3284438},
abstract = {Most of agents that learn policy for tasks with reinforcement learning (RL) lack the ability to communicate with people, which makes human-agent collaboration challenging. We believe that, in order for RL agents to comprehend utterances from human colleagues, RL agents must infer the mental states that people attribute to them because people sometimes infer an interlocutor's mental states and communicate on the basis of this mental inference. This paper proposes PublicSelf model, which is a model of a person who infers how the person's own behavior appears to their colleagues. We implemented the PublicSelf model for an RL agent in a simulated environment and examined the inference of the model by comparing it with people's judgment. The results showed that the agent's intention that people attributed to the agent's movement was correctly inferred by the model in scenes where people could find certain intentionality from the agent's behavior.},
booktitle = {Proceedings of the 6th International Conference on Human-Agent Interaction},
pages = {3–10},
numpages = {8},
keywords = {theory of mind, human-agent interaction, reinforcement learning, bayesian inference, public self-awareness, publicself model},
location = {Southampton, United Kingdom},
series = {HAI '18}
}
@inproceedings{Fukuchi_2017,
author = {Fukuchi, Yosuke and Osawa, Masahiko and Yamakawa, Hiroshi and Imai, Michita},
title = {Autonomous Self-Explanation of Behavior for Interactive Reinforcement Learning Agents},
year = {2017},
isbn = {9781450351133},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3125739.3125746},
doi = {10.1145/3125739.3125746},
abstract = {In cooperation, the workers must know how co-workers behave. However, an agent's policy, which is embedded in a statistical machine learning model, is hard to understand, and requires much time and knowledge to comprehend. Therefore, it is difficult for people to predict the behavior of machine learning robots, which makes Human Robot Cooperation challenging. In this paper, we propose Instruction-based Behavior Explanation (IBE), a method to explain an autonomous agent's future behavior. In IBE, an agent can autonomously acquire the expressions to explain its own behavior by reusing the instructions given by a human expert to accelerate the learning of the agent's policy. IBE also enables a developmental agent, whose policy may change during the cooperation, to explain its own behavior with sufficient time granularity.},
booktitle = {Proceedings of the 5th International Conference on Human Agent Interaction},
pages = {97–101},
numpages = {5},
keywords = {interactive reinforcement learning, instruction-based behavior explanation, human robot cooperation},
location = {Bielefeld, Germany},
series = {HAI '17}
}
@incollection{Fukuchi_2017iconip, doi = {10.1007/978-3-319-70087-8_11}, url = {https://doi.org/10.1007%2F978-3-319-70087-8_11}, year = 2017, publisher = {Springer International Publishing}, pages = {100--108}, author = {Yosuke Fukuchi and Masahiko Osawa and Hiroshi Yamakawa and Michita Imai}, title = {Application of Instruction-Based Behavior Explanation to a Reinforcement Learning Agent with Changing Policy}, booktitle = {Neural Information Processing}}
@inproceedings{DBLP:conf/hai/MatsumoriFOI18,
  author    = {Shoya Matsumori and
               Yosuke Fukuchi and
               Masahiko Osawa and
               Michita Imai},
  editor    = {Michita Imai and
               Tim Norman and
               Elizabeth Sklar and
               Takanori Komatsu},
  title     = {Do Others Believe What {I} Believe?: Estimating How Much Information
               is being Shared by Utterance Timing},
  booktitle = {Proceedings of the 6th International Conference on Human-Agent Interaction, {HAI} 2018, Southampton, United Kingdom, December 15-18, 2018},
  pages     = {301--309},
  publisher = {{ACM}},
  year      = {2018},
  url       = {https://doi.org/10.1145/3284432.3284461},
  doi       = {10.1145/3284432.3284461},
  timestamp = {Thu, 14 Oct 2021 09:57:07 +0200},
  biburl    = {https://dblp.org/rec/conf/hai/MatsumoriFOI18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1145/3490099.3511116,
author = {Shibata, Ryoichi and Matsumori, Shoya and Fukuchi, Yosuke and Maekawa, Tomoyuki and Kimoto, Mitsuhiko and Imai, Michita},
title = {Utilizing Core-Query for Context-Sensitive Ad Generation Based on Dialogue},
year = {2022},
isbn = {9781450391443},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490099.3511116},
doi = {10.1145/3490099.3511116},
abstract = {In this work, we present a system that sequentially generates advertisements within the context of a dialogue. Advertisements tailored to the user have long been displayed on the digital signage in stores, on web pages, and on smartphone applications. Advertisements will work more effectively if they are aware of the context of the dialogue between the users. Creating an advertising sentence as a query and searching the web by using that query is one way to present a variety of advertisements, but there is currently no method to create an appropriate search query for the search in accordance with the dialogue context. Therefore, we developed a method called the Conversational Context-sensitive Advertisement generator (CoCoA). The novelty of CoCoA is that advertisers simply need to prepare a few abstract phrases, called Core-Queries, and then CoCoA dynamically transforms the Core-Queries into complete search queries in accordance with the dialogue context. Here, “transforms” means to add words related to the context in the dialogue to the prepared Core-Queries. The transformation is enabled by a masked word prediction technique that predicts a word that is hidden in a sentence. Our attempt is the first to apply masked word prediction to a web information retrieval framework that takes into account the dialogue context. We asked users to evaluate the search query presented by CoCoA against the dialogue text of multiple domains prepared in advance and found that CoCoA could present more contextual and effective advertisements than Google Suggest or a method without the query transformation. In addition, we found that CoCoA generated high-quality advertisements that advertisers had not expected when they created the Core-Queries.},
booktitle = {27th International Conference on Intelligent User Interfaces},
pages = {734–745},
numpages = {12},
	keywords = {context, query generation, advertisement, mask prediction, dialogue},
location = {Helsinki, Finland},
series = {IUI '22}
}
@article{20192019,
  title={2019 年度日本認知科学会サマースクール参加報告},
  author={福地 庸介 and 鳥羽山 莉沙},
  journal={認知科学},
  volume={26},
  number={4},
  pages={524--526},
  year={2019},
  publisher={日本認知科学会}
}
@article{1573668927856247424,
author={柴田 遼一 and 吉野 哲平 and 松森 匠哉 and 福地 庸介 and 木本 充彦 and 今井 倫太},
title={不完全な検索クエリにおける対話履歴からの検索ワード補完手法の検討},
journal={情報処理学会第83回全国大会講演論文集},
year={2021},
month={03},
volume={2021},
number={1},
pages={411-412},
URL={https://cir.nii.ac.jp/crid/1573668927856247424}
}
@article{1572824502926346240,
author={渡邊 悠太 and 福地 庸介 and 前川 知行 and 今井 倫太},
title={行動情報と発話情報の組み合わせによる信念と欲求の逐次的推測モデルの検討},
journal={情報処理学会第83回全国大会講演論文集},
year={2021},
month={03},
volume={2021},
number={1},
pages={211-212},
URL={https://cir.nii.ac.jp/crid/1572824502926346240}
}
@article{1574231877809662848,
author={金沢 壮真 and 松森 匠哉 and 新行内 浩輔 and 福地 庸介 and 今井 倫太},
title={視覚情報を用いた対話型物体特定タスクにおける質問数削減手法の検討},
journal={情報処理学会第83回全国大会講演論文集},
year={2021},
month={03},
volume={2021},
number={1},
pages={417-418},
URL={https://cir.nii.ac.jp/crid/1574231877809662848}
}
@article{uchiumi2021,
  title={曖昧性解消における視覚的注意へのトップダウン介入},
  author={内海 佑麻 and 福地 庸介 and 木本 充彦 and 今井 倫太},
  journal={人工知能学会全国大会論文集},
  volume={JSAI2021},
  number={ },
  pages={1H2GS1a04-1H2GS1a04},
  year={2021},
  doi={10.11517/pjsai.JSAI2021.0_1H2GS1a04}
}
@article{hongo2020,
  title={対話支援に向けた言語情報と画像情報の対応付けによる話者のアテンション可視化},
  author={本郷 望実 and 松森 匠哉 and 福地 庸介 and 前川 知行 and 今井 倫太},
  journal={人工知能学会研究会資料 言語・音声理解と対話処理研究会},
  volume={90},
  number={ },
  pages={20},
  year={2020},
  doi={10.11517/jsaislud.90.0_20}
}
@article{tsuchiya2021,
  title={アクショングラフを用いた 「位置情報と発話内容をもとにした」 信念と欲求の推定システム},
  author={土屋碧渡 and 川崎陽祐 and 渡邊悠太 and 佐藤夏樹 and 福地庸介 and 松森匠哉 and 前川知行 and 髙橋正樹 and 今井倫太},
  journal={電子情報通信学会技術研究報告; 信学技報},
  publisher={電子情報通信学会},
  year={2021}
}
@article{fukuchi2017_3,
  title={異種エージェントへの教示に向けたInstruction-based Behavior Explanationの応用の検討},
  author={福地 庸介 and 大澤 正彦 and 山川 宏 and 今井 倫太},
  journal={人工知能学会第二種研究会資料},
  volume={2017},
  number={AGI-006},
  pages={07},
  year={2017},
  doi={10.11517/jsaisigtwo.2017.AGI-006_07}
}
@article{fukuchi2017_2,
  title={深層強化学習エージェントの自己モデル獲得と行動目標説明表現の生成},
  author={福地 庸介 and 大澤 正彦 and 岨野 太一 and 山川 宏 and 今井 倫太},
  journal={人工知能学会第二種研究会資料},
  volume={2017},
  number={AGI-005},
  pages={08},
  year={2017},
  doi={10.11517/jsaisigtwo.2017.AGI-005_08}
}

@article{fukuchi2017,
  title={深層強化学習エージェントの自己モデルによる意図の解釈},
  author={福地庸介 and 大澤正彦 and 岨野太一 and 山川宏 and 今井倫太},
  journal={第 79 回全国大会講演論文集},
  volume={2017},
  number={1},
  pages={655--656},
  year={2017}
}
@inproceedings{fukuchi2018,
  title={人間の環世界から見たエージェントモデル--AI Safety の実現に向けて},
  author={福地庸介 and 大澤正彦 and 山川宏 and 今井倫太},
  booktitle={人工知能学会全国大会論文集 第 32 回 (2018)},
  pages={3J105--3J105},
  year={2018},
  organization={一般社団法人 人工知能学会}
}
@article{matsumori2018,
  title={ユーザモデルにもとづいて発言タイミングを決定するプレディクティブチャットボット},
  author={松森匠哉 and 大澤正彦 and 福地庸介 and 今井倫太},
  journal={第 80 回全国大会講演論文集},
  volume={2018},
  number={1},
  pages={419--420},
  year={2018}
}
@inproceedings{satogata2019,
  title={ユーザの閲覧行動に基づきパノラマ画像データを選択する適応型ストリートビューの開発},
  author={里形理興 and 滝口啓介 and 福地庸介 and 今井倫太},
  booktitle={人工知能学会全国大会論文集 第 33 回 (2019)},
  pages={1O2J1202--1O2J1202},
  year={2019},
  organization={一般社団法人 人工知能学会}
}
@article{satogata2020q,
  title={Q-Mapping: 行動価値関数を利用したユーザ操作に対する解釈の適応的獲得},
  author={里形理興 and 妹尾卓磨 and 福地庸介 and 今井倫太},
  journal={人工知能学会全国大会論文集},
  volume={2020},
  pages={3Rin446--3Rin446},
  year={2020},
  publisher={一般社団法人 人工知能学会}
}
@inproceedings{shingyo2020,
  title={分散表現空間内の文脈の推移に着目したワード人狼における発話分析},
  author={新行内浩輔 and 松森匠哉 and 福地庸介 and 阿部佑樹 and 今井倫太},
  booktitle={人工知能学会全国大会論文集 第 34 回 (2020)},
  pages={3Q1GS904--3Q1GS904},
  year={2020},
  organization={一般社団法人 人工知能学会}
}
@inproceedings{yoshino2020scake,
  title={SCAKE: 文脈と重要語の逐次的並列推定},
  author={吉野哲平 and 松森匠哉 and 福地庸介 and 滝本佑介 and 今井倫太},
  booktitle={人工知能学会全国大会論文集 第 34 回 (2020)},
  pages={3Q1GS903--3Q1GS903},
  year={2020},
  organization={一般社団法人 人工知能学会}
}
@inproceedings{maekawa2021,
	title={文脈の中で相互理解感を形作る推薦対話システム},
	author={前川 知行 and 松森 匠哉 and  福地 庸介 and  今井 倫太},
	booktitle={日本認知科学会第38回大会},
	pages={40--46},
	year={2021},
}
@inproceedings{takarada2020,
	title={情報の非対称性を含む Legible Motion に対する印象的評価の検証},
	author={宝田 悠 and 福地 庸介 and  今井 倫太 and  高橋 達二},
	booktitle={日本認知科学会第37回大会},
	year={2020}
}
@inproceedings{takarada2019,
	title={情報の非対称性を含む Legible Motion に対する印象的評価の検証},
	author={宝田 悠 and 福地 庸介 and  今井 倫太 and  高橋 達二},
	booktitle={日本認知科学会第36回大会},
	year={2019}
}
@misc{https://doi.org/10.48550/arxiv.2005.14662,
  doi = {10.48550/ARXIV.2005.14662},
  url = {https://arxiv.org/abs/2005.14662},
  author = {Takimoto, Yusuke and Fukuchi, Yosuke and Matsumori, Shoya and Imai, Michita},
  keywords = {},
  title = {SLAM-Inspired Simultaneous Contextualization and Interpreting for Incremental Conversation Sentences},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{https://doi.org/10.48550/arxiv.2205.07202,
  doi = {10.48550/ARXIV.2205.07202},
  
  url = {https://arxiv.org/abs/2205.07202},
  
  author = {Matsumori, Shoya and Okuoka, Kohei and Shibata, Ryoichi and Inoue, Minami and Fukuchi, Yosuke and Imai, Michita},
  
  keywords = {},
  
  title = {Mask and Cloze: Automatic Open Cloze Question Generation using a Masked Language Model},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{https://doi.org/10.48550/arxiv.2206.11813,
  doi = {10.48550/ARXIV.2206.11813},
  
  url = {https://arxiv.org/abs/2206.11813},
  
  author = {Yoshino, Teppei and Fukuchi, Yosuke and Matsumori, Shoya and Imai, Michita},
  
  keywords = {},
  
  title = {Chat, Shift and Perform: Bridging the Gap between Task-oriented and Non-task-oriented Dialog Systems},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{sm2022,
  title={マスク言語モデルを利用したOpen Cloze問題の自動生成},
  author={松森 匠哉 and 奥岡 耕平 and 柴田 遼一 and 井上 南 and 吉野 哲平 and 福地 庸介 and 岩沢 透 and 今井 倫太},
  journal={人工知能学会全国大会論文集},
  volume={JSAI2022},
  number={ },
  pages={3N4GS1004-3N4GS1004},
  year={2022},
  doi={10.11517/pjsai.JSAI2022.0_3N4GS1004}
}
@article{hasegawa2022advantage,
  title={Advantage 関数を用いたコントローラキャリブレーションによるユーザ好みのマッピングの獲得},
  author={長谷川麟太郎 and 福地庸介 and 奥岡耕平 and 今井倫太},
  journal={情報処理学会第84 回全国大会講演論文集},
  volume={2022},
  number={1},
  pages={39--40},
  year={2022}
}
@article{tsuchiya2022,
  title={買い物支援ロボットに向けた実世界における信念と欲求の逐次推定モデルの検討},
  author={土屋碧渡 and 川崎陽祐 and 渡邊悠太 and 佐藤夏樹 and 福地庸介 and 松森匠哉 and 前川知行 and 髙橋正樹 and 今井倫太},
  journal={情報処理学会第84 回全国大会講演論文集},
  volume={2022},
  number={1},
  pages={95--96},
  year={2022}
}
@article{hais2023,
  title={信頼度推定にもとづく信頼較正キューの選択的提示},
  author={福地庸介 and 山田誠二},
  journal={HAIシンポジウム2023},
  year={2023},
  url={https://hai-conference.net/symp2023/proceedings/html/paper/paper-G-14.html}
}
@inproceedings{https://doi.org/10.48550/arxiv.2302.09995,
  url = {https://escholarship.org/uc/item/8zp6g0mj},
  author = {Fukuchi, Yosuke and Yamada, Seiji},
  title = {Selectively Providing Reliance Calibration Cues With Reliance Prediction},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={45},
  pages={1579-1586},
  year = {2023},
}

@inproceedings{iros2023,
  title={Selective Presentation of AI Object Detection Results While Maintaining Human Reliance},
  author={Fukuchi, Yosuke and Yamada, Seiji},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year={2023},
  organization={IEEE},
  pages={3527-3532},
  url={https://ieeexplore.ieee.org/document/10341684},
  doi={10.1109/IROS55552.2023.10341684}
}
@inproceedings{hai2023maehigashi,
author = {Maehigashi, Akihiro and Fukuchi, Yosuke and Yamada, Seiji},
title = {Experimental Investigation of Human Acceptance of AI Suggestions with Heatmap and Pointing-Based XAI},
year = {2023},
isbn = {9798400708244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623809.3623834},
doi = {10.1145/3623809.3623834},
abstract = {This study investigated how displaying an AI attention heatmap influences human acceptance of the AI’s suggestions in accordance with the interpretability of the heatmap. We conducted an experiment using a visual task where the participants were required to decide whether to accept or reject an AI’s suggestions. The participants could see the suggestions with an AI attention heatmap, the heatmap with the AI pointing to it (displayed as a laser dot cursor), the heatmap with a robot pointing (a robot using a stick to point to the AI heatmap displayed on a tablet), or no heatmap. The experimental results revealed that human acceptance of AI suggestions differed depending on the interpretability of the heatmap, especially when the heatmap was displayed with AI pointing. Also, additional analysis revealed an effect on acceptance due to the AI pointing to the heatmap that was found only in a high-task difficulty situation. An AI pointing to its attention heatmap is considered to trigger people to reason about particular AI processes and accept its suggestions. This study showed that an AI pointing to its attention heatmap could be used to control human behaviors in human-agent interaction.},
booktitle = {Proceedings of the 11th International Conference on Human-Agent Interaction},
pages = {291–298},
numpages = {8},
keywords = {XAI, Reliance and compliance, Robot, AI, Saliency map, Heatmap, Trust, Pointing},
location = {<conf-loc>, <city>Gothenburg</city>, <country>Sweden</country>, </conf-loc>},
series = {HAI '23}
}
@article{jsai2023,
  title={信頼の獲得に向けた物体認識結果の選択的提示手法の検討},
  author={福地 庸介 and 山田 誠二},
  journal={人工知能学会全国大会論文集},
  volume={JSAI2023},
  number={ },
  pages={3I5OS4c03-3I5OS4c03},
  year={2023},
  doi={10.11517/pjsai.JSAI2023.0_3I5OS4c03}
}
@article{jsai2023maehigashi,
  title={目標と注意の説明を用いたXAI利用のモデル化},
  author={前東 晃礼 and 福地 庸介 and 山田 誠二},
  journal={人工知能学会全国大会論文集},
  volume={JSAI2023},
  number={ },
  pages={3I5OS4c05-3I5OS4c05},
  year={2023},
  doi={10.11517/pjsai.JSAI2023.0_3I5OS4c05}
}
@incollection{jimin_reverse1,
  title={デジタル社会推進本部の組織及び運営に関する提言},
  author={飯田 森 and 徳力 創一朗 and 福地 庸介 and 古井 康介 and 鑓水 陽子},
  booktitle={自由民主党・党改革実行本部 リバースメンター 自由民主党のデジタル政策に関する提言集},
  pages={8-12},
  year={2023}
}
@incollection{jimin_reverse2,
  title={選挙DXの推進を求める提言},
  author={福地 庸介 and 古井 康介 and 飯田 森 and 鑓水 陽子 and  徳力 創一朗 and 合田 瞳},
  booktitle={自由民主党・党改革実行本部 リバースメンター 自由民主党のデジタル政策に関する提言集},
  pages={27-34},
  year={2023}
}
@incollection{jimin_reverse3,
  title={妊娠及び育児に伴う身体的及び精神的不安を低減するデジタル化推進を 求める提言},
  author={古井 康介 and 鑓水 陽子 and 福地 庸介 and 飯田 森 and 永見日菜子},
  booktitle={自由民主党・党改革実行本部 リバースメンター 自由民主党のデジタル政策に関する提言集},
  pages={54-67},
  year={2023}
}
@article{hais2024,
  title={人-XAIインタラクションにおけるユーザ意思決定モデルの検討},
  author={福地庸介 and 山田誠二},
  journal={HAIシンポジウム2024},
  year={2024},
  url={https://hai-conference.net/symp2024/proceedings/html/paper/paper-G-13.html}
}
@misc{jsdp2024,
  title={機械学習を用いた教育動画コンテンツ処理に関する基礎検討},
  author={福地庸介},
  journal={日本発達心理学会 第35回全国大会 ラウンドテーブル「デジタルネイティブ世代のメディア視聴とその影響 実生活環境下におけるテレビ視聴に関する発達神経科学的縦断研究」},
  year={2024}
}
@article{jsai_fukuchi_2024,
  title={人-XAIインタラクションにおける説明強調点の動的選択手法の検討},
  author={福地 庸介 and 山田 誠二},
  journal={人工知能学会全国大会論文集},
  volume={JSAI2024},
  number={ },
  pages={4T3OS6d02-4T3OS6d02},
  year={2024},
  doi={10.11517/pjsai.JSAI2024.0_4T3OS6d02}
}
@article{jsai_maehigashi_2024,
  title={視覚的課題におけるXAIデザインの検討},
  author={前東 晃礼 and 福地 庸介 and 山田 誠二},
  journal={人工知能学会全国大会論文集},
  volume={JSAI2024},
  number={ },
  pages={4T3OS6d01-4T3OS6d01},
  year={2024},
  doi={10.11517/pjsai.JSAI2024.0_4T3OS6d01}
}
@misc{cogsciMeetUp2024,
	title={HAIでCogSciを牛耳るために},
	author={福地庸介},
  booktitle={CogSci Meetpu 2024 in Hamamatsu}, 
  year={2024}
}
@misc{CCWS2024,
	title={Cognitive Human-AI Interaction},
	author={福地庸介},
  booktitle={第23回 認知的コミュニケーションワークショップ}, 
  year={2024}
}

@misc{VRGakkai2024,
	title={空間提示手法と指令入力手法の違いがVR空間での多重身体認知に及ぼす影響},
	author={芹澤尚舜 and 福地庸介 and ヤェム ヴィボル and 池井 寧 and 西内信之},
	booktitle={第29回日本バーチャルリアリティ学会大会},
	pages={3D2-04},
	url={https://conference.vrsj.org/ac2024/program/doc/3D2-04.pdf},
	year={2024}
}
@misc{VRGakkai2024_2,
	title={話者CGモデルを実空間アバターロボットに提示するXR遠隔対話システム },
	author={米田 悠人 and 小島 優希也 and 福地 庸介 and ヤェム ヴィボル and 池井 寧 and 西内 信之},
	booktitle={第29回日本バーチャルリアリティ学会大会},
	pages={1B2-10},
	url={https://conference.vrsj.org/ac2024/program/doc/1B2-10.pdf},
	year={2024}
}
@misc{HAIS2025_conspiracy,
	title={ウェブメディア探索を通じた信念形成の認知モデル化の検討},
	author={福地 庸介},
	  booktitle={HAIシンポジウム2025},
	  pages={G-4},
	  url={https://hai-conference.net/symp2025/proceedings/html/paper/paper-G-4.html},
	  year={2025}
}
@misc{HAIS2025_XAI,
	title={コミュニケーションロボットを用いた適応的人-XAIインタラクションに向けて},
	author={福地 庸介 and 山田 誠二},
	  booktitle={HAIシンポジウム2025},
	  pages={P2-17},
	  url={https://hai-conference.net/symp2025/proceedings/html/paper/paper-P2-17.html},
	  year={2025}
}
@misc{HAIS2025_ito,
	title={遠隔回想法のための肩乗り型ファシリテーションロボットシステムの提案},
	author={伊藤 龍之介 and 福地 庸介 and 松室 拓秀 and 中西 建心 and 今井 倫太},
	  booktitle={HAIシンポジウム2025},
	  pages={P2-11},
	  url={https://hai-conference.net/symp2025/proceedings/html/paper/paper-P2-11.html},
	  year={2025}
}
@misc{BioX25_nakamura,
	title={マニューシャマッチングを用いたオンライン署名認証の提案},
	author={中村壮 and 福地庸介 and 西内信之},
	  booktitle={バイオメトリクス研究会（BioX）},
	  pages={BioX2024-91},
	  year={2025}
}
@misc{VirtualGakkai2024,
	title={リアルアバタを重畳した実空間ロボットを用いたXR遠隔対話システムの構築と定性評価},
	author={米田 悠人 and 小島 優希也 and 福地 庸介 and ヤェム ヴィボル and 池井 寧 and 西内 信之},
	booktitle={バーチャル学会（VCONF2024）},
	year={2024}
}

@inproceedings{kishi2024password,
  author    = {岸 宏海 and 福地 庸介 and 西内 信之},
  title     = {日本語および絵文字パスワードの想起性と安全性についての検討},
  booktitle = {日本人間工学会アーゴデザイン部会コンセプト事例発表会},
  year      = {2024},
  month     = {9}
}

@inproceedings{wada2024ui,
  author    = {和田 圭太 and 西内 信之 and 福地 庸介},
  title     = {画像生成AIによるユーザインタフェース制作支援の検証},
  booktitle = {日本人間工学会アーゴデザイン部会コンセプト事例発表会},
  year      = {2024},
  month     = {9}
}

@inproceedings{tsuchiya2024gaze,
  author    = {土屋 里紗 and 福地 庸介 and 西内 信之},
  title     = {機械学習を用いて視線情報からユーザインターフェース作業の習熟度推定},
  booktitle = {日本人間工学会アーゴデザイン部会コンセプト事例発表会},
  year      = {2024},
  month     = {9}
}

@inproceedings{miyamoto2024telepresence,
  author    = {宮本 莉里花 and 福地 庸介 and 西内 信之 and ヤェム ヴィボル and 池井 寧},
  title     = {二つの遠隔空間でのテレプレゼンスにおける視点切替の際の認知的負荷に関する研究},
  booktitle = {日本人間工学会アーゴデザイン部会コンセプト事例発表会},
  year      = {2024},
  month     = {9}
}
